{
  "hash": "a7324a4e143f3c2e3b0ae21f4145843c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05-Distribution and Confidence Intervals of Clementines\"\ndate: '2023-11-14'\n---\n\n\n\n# Introduction\n\nThe example aims to demonstrate estimation and interpretation of confidence\nintervals. At the end, the two samples are compared with respect to variance and\nmean values.\n\nThe experimental hypotheses was, that weight and size of two samples of Clementine fruits differ. The result is to be visualized with bar charts or box plots. We use only the weight as an example, analysis of the other statistical parameters is left as an optional exercise.\n\nWe can now derive the following statistical hypotheses **about the variance:**\n\n* $H_0$: The variance of both samples is the same.\n* $H_a$: The samples have different variance.\n\n**and about the mean:**\n\n* $H_0$: The mean of both samples is the same.\n* $H_a$: The mean values of the samples are different.\n\n# Material and Methods\n\nThe data set consists of two samples of Clementines from the same shop. Weight, \nwidth and height of the fruits were measured with a scale and a caliper.\n\nThe statistical analysis is performed with the **R** software for statistical \ncomputing and graphics [@RCore] and the following packages \n[@Wickham2016; @Wickham2023; @Warnes2024]:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"gplots\")  # contains barplot2 with error bars\nlibrary(\"dplyr\")   # for pipelines, group_by and summarize\nlibrary(\"ggplot2\") # modern plotting package \"grammar of graphics\"\n```\n:::\n\n\n\n# Data Analysis\n\n## Prepare and inspect data\n\n* Download the data set `fruits-2023-hse.csv` and use one of RStudio's \"Import Dataset\" wizards.\n* A better alternative is to use `read.csv()`.\n* The data set is available in OPAL[^OPAL] or from: [https://raw.githubusercontent.com/tpetzoldt/datasets/refs/heads/main/data/fruits-2023-hse.csv](https://raw.githubusercontent.com/tpetzoldt/datasets/refs/heads/main/data/fruits-2023-hse.csv)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  ... do it\n```\n:::\n\n\n* plot everything, just for testing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fruits)\n```\n:::\n\n\n* split table for box1 and box2:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox1 <- subset(fruits, brand == \"box1\")\nbox2 <- subset(fruits, brand == \"box2\")\n```\n:::\n\n\n* compare weight of both groups:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(box1$weight, box2$weight, names=c(\"box1\", \"box2\"))\n```\n:::\n\n**Note:** It is also possible to use `boxplot` with the model formula syntax. \nThis is the preferred way, because it does not require to split the data set beforehand:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(weight ~ brand, data = fruits)\n```\n:::\n\n\n\n\n## Check distribution\n\nWe can check the shape of distribution graphically. If mean values of the samples \ndiffer much, it has to be done separately for each sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use `hist`, `qqnorm`, `qqline`\n# ...\n```\n:::\n\n\n## Sample statistics\n\nIf we assume normal distribution of the data, we can estimate an approximate\n prediction interval from the sample parameters, i.e. in which size range\n we find 95% of the weights within one group.\n \nWe first calculate mean, sd, N and se for \"box1\" data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox1.mean <- mean(box1$weight)\nbox1.sd   <- sd(box1$weight)\nbox1.N    <- length(box1$weight)\nbox1.se   <- box1.sd/sqrt(box1.N)\n```\n:::\n\n\nThen we estimate the two-sided 95% prediction interval for the sample, assuming normal\n  distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox1.95 <- box1.mean + c(-1.96, 1.96) * box1.sd\nbox1.95\n```\n:::\n\n\nInstead of using 1.96, we could also use the quantile function of the normal distribution instead, e.g. `qnorm(0.975)`for the upper interval or `qnorm(c(0.025, 0.975))` for the lower and upper.\n\n\nIf the data set is large enough, we can compare the prediction interval from above\nwith the  **empirical quantiles**, i.e. take it directly from the data. Here we\ndo not assume a normal or any other distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(box1$weight, p = c(0.025, 0.975))\n```\n:::\n\n\nNow we plot the data and indicate the 95% interval:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(box1$weight)\nabline(h = box1.95, col=\"red\")\n```\n:::\n\n\n... and the same as histogram:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(box1$weight)\nabline(v = box1.95, col=\"red\")\nrug(box1$weight, col=\"blue\")\n```\n:::\n\n\n## Confidence interval of the mean\n\nThe **confidence interval** of the mean tells us how precise a mean value was \nestimated from data.\nIf the sample size is \"large enough\", the distribution of the raw data does not\nnecessarily need to be normal distributed, because then mean values tend to approximate\na normal distribution due to the central limit theorem.\n\n### Confidence interval of the mean for the \"box1\" data\n\n* Calculate the confidence interval of the mean value of the \"box1\" data set,\n* use +/- 1.96 or (better) the quantile of the t-distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox1.ci <- box1.mean + qt(p = c(0.025, 0.975), df = box1.N-1) * box1.se\n```\n:::\n\n\nNow indicate the confidence interval of the mean in the histogram.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabline(v = box1.ci, col=\"red\")\n```\n:::\n\n\n### Confidence interval for the mean of the \"box2\" data\n\nWe could now in principle do the same as above for the \"box2\" sample, but this \nwould be rather cumbersome and boring. A more efficient method from package **dplyr** \nis shown below.\n\n\n# Compare samples with F- and t-Test\n\n**Null Hypothesis:** Both samples have the same mean weight and variance.\n\n**Alternative:** The mean weight (and possibly also the variance) differs. The fruits bought on Friday and on Tuesday had a different price, so we expect a different quality and probably different size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(weight ~ brand, data = fruits)\n```\n:::\n\n\nPerform also the classical t-test (`var.equal=TRUE`) and the F-test (`var.test`).\nCalculate absolute and relative effect size (mean differences) and interpret\nthe results of all 3 tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# var.test(...)\n# t.test(...)\n# ...\n```\n:::\n\n\n# Summary statistics and CI with **tidyverse**\n\nThe following shows how to calculate summary statistics in a more modern and efficient way.\n\nThe approach uses the **dplyr** and **ggplot2** packages from the so-called \n**tidyverse** family of packages [@Wickham2019, @Wickham2023]. Furthermore, we \nuse the pipeline operator `|>`, that transfers the output of one data manipulation \nstep directly to the next.\n\nSome slides about the use of pipelines can be found under [https://tpetzoldt.github.io/elements/](https://tpetzoldt.github.io/elements/)\n\n## Calculation of summary statistics with **dplyr**\n\nSummarizing can be done with two functions, `group_by` that adds grouping information \nto a data frame and `summarize` to calculate summary statistics. In the following, we use the full\ndata set with 4 groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"dplyr\")\nfruits <- read.csv(\"fruits-2023-hse.csv\")\n\nstats <-\n  fruits |>\n    group_by(brand) |>\n    summarize(mean = mean(weight), sd=sd(weight), N=length(weight), se=sd/sqrt(N),\n              lwr = mean + qt(p = 0.025, df = N-1) * se,\n              upr = mean + qt(p = 0.975, df = N-1) * se\n             )\n\nstats\n```\n:::\n\n\n## Barchart and errorbars with **ggplot2**\n\nWe can then use the table of summary statistics directly for a bar chart.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"ggplot2\")\nstats |>\n  ggplot(aes(x=brand, y=mean, min=lwr, max=upr))  +\n    geom_col() + geom_errorbar()\n```\n:::\n\n\n## Additional tasks\n\nRepeat the analysis with other properties of the fruits, e.g. width and height. \nCreate box plots, analyse distribution, create bar charts.\n\n\n# References\n\n[^OPAL]: OPAL is the learning management system used at TU Dresden.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}